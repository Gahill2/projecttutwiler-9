import os
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import time
from normalize import normalize_nvd, normalize_cisa_kev, normalize_osv, build_embedding_text, chunk_text
from pinecone_client import get_index
from adapters.ollama import get_embedding

# Stats tracking
_stats = {
    "nvd": {"total_chunks": 0, "last_refresh_at": None},
    "cisa_kev": {"total_chunks": 0, "last_refresh_at": None},
    "osv": {"total_chunks": 0, "last_refresh_at": None}
}

def get_stats() -> Dict[str, Any]:
    """Get current stats"""
    return _stats.copy()

def fetch_nvd(window_days: int = 3, api_key: Optional[str] = None) -> List[Dict[str, Any]]:
    """Fetch CVEs from NVD API"""
    base_url = os.getenv("NVD_API_BASE", "https://services.nvd.nist.gov/rest/json/cves/2.0")
    
    # Calculate date range
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=window_days)
    
    last_mod_start = start_date.strftime("%Y-%m-%dT%H:%M:%S.000")
    last_mod_end = end_date.strftime("%Y-%m-%dT%H:%M:%S.000")
    
    all_cves = []
    start_index = 0
    results_per_page = 2000
    
    headers = {}
    if api_key:
        headers["apiKey"] = api_key
    
    while True:
        params = {
            "lastModStartDate": last_mod_start,
            "lastModEndDate": last_mod_end,
            "startIndex": start_index,
            "resultsPerPage": results_per_page
        }
        
        try:
            response = requests.get(base_url, params=params, headers=headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            vulnerabilities = data.get("vulnerabilities", [])
            if not vulnerabilities:
                break
            
            for vuln in vulnerabilities:
                all_cves.append(vuln.get("cve", {}))
            
            total_results = data.get("totalResults", 0)
            if start_index + len(vulnerabilities) >= total_results:
                break
            
            start_index += len(vulnerabilities)
            
            # Rate limiting: NVD allows 5 requests per 30 seconds without API key
            # With API key: 50 requests per 30 seconds
            time.sleep(0.2)  # Conservative delay
            
        except requests.RequestException as e:
            print(f"Error fetching NVD data: {e}")
            break
    
    return all_cves

def fetch_cisa_kev() -> List[Dict[str, Any]]:
    """Fetch CISA Known Exploited Vulnerabilities"""
    url_env = os.getenv("CISA_KEV_JSON", "").strip()
    url = url_env if url_env else "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        vulnerabilities = data.get("vulnerabilities", [])
        return vulnerabilities
    except requests.RequestException as e:
        print(f"Error fetching CISA KEV data: {e}")
        return []

def fetch_osv(query: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Fetch from OSV.dev API"""
    base_url = os.getenv("OSV_API_BASE") or "https://api.osv.dev"
    url = f"{base_url}/v1/query"
    
    try:
        response = requests.post(url, json=query, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        vulns = data.get("vulns", [])
        return vulns
    except requests.RequestException as e:
        print(f"Error fetching OSV data: {e}")
        return []

def ingest_normalized(normalized: Dict[str, Any], namespace: str) -> int:
    """Ingest a normalized CVE: chunk, embed, upsert to Pinecone"""
    embedding_text = build_embedding_text(normalized)
    chunks = chunk_text(embedding_text)
    
    index = get_index()
    vectors_to_upsert = []
    
    for i, chunk in enumerate(chunks):
        try:
            embedding = get_embedding(chunk)
            chunk_id = f"{normalized['id']}_chunk_{i}"
            
            metadata = {
                "id": normalized["id"],
                "source": normalized["source"],
                "chunk": chunk,
                "severity": normalized.get("severity", "UNKNOWN"),
                "cwe": ",".join(normalized.get("cwe", [])),
                "published": normalized.get("published", ""),
            }
            
            vectors_to_upsert.append({
                "id": chunk_id,
                "values": embedding,
                "metadata": metadata
            })
        except Exception as e:
            print(f"Error embedding chunk {i} for {normalized['id']}: {e}")
            continue
    
    if vectors_to_upsert:
        try:
            index.upsert(vectors=vectors_to_upsert, namespace=namespace)
            return len(vectors_to_upsert)
        except Exception as e:
            print(f"Error upserting to Pinecone: {e}")
            return 0
    
    return 0

def refresh_all() -> Dict[str, Any]:
    """Refresh all enabled sources"""
    results = {
        "nvd": {"count": 0, "chunks": 0},
        "cisa_kev": {"count": 0, "chunks": 0},
        "osv": {"count": 0, "chunks": 0}
    }
    
    # Fetch and ingest NVD
    try:
        window_days_str = os.getenv("CVE_REFRESH_WINDOW_DAYS", "3").strip()
        window_days = int(window_days_str) if window_days_str and window_days_str.isdigit() else 3
        api_key = os.getenv("NVD_API_KEY") or None
        nvd_cves = fetch_nvd(window_days, api_key)
        
        for cve in nvd_cves:
            normalized = normalize_nvd(cve)
            chunks = ingest_normalized(normalized, "nvd")
            results["nvd"]["count"] += 1
            results["nvd"]["chunks"] += chunks
        
        _stats["nvd"]["total_chunks"] = results["nvd"]["chunks"]
        _stats["nvd"]["last_refresh_at"] = datetime.utcnow().isoformat()
    except Exception as e:
        print(f"Error refreshing NVD: {e}")
    
    # Fetch and ingest CISA KEV
    try:
        cisa_kevs = fetch_cisa_kev()
        
        for kev in cisa_kevs:
            normalized = normalize_cisa_kev(kev)
            chunks = ingest_normalized(normalized, "cisa_kev")
            results["cisa_kev"]["count"] += 1
            results["cisa_kev"]["chunks"] += chunks
        
        _stats["cisa_kev"]["total_chunks"] = results["cisa_kev"]["chunks"]
        _stats["cisa_kev"]["last_refresh_at"] = datetime.utcnow().isoformat()
    except Exception as e:
        print(f"Error refreshing CISA KEV: {e}")
    
    # OSV is optional (feature flag)
    osv_enabled = os.getenv("OSV_ENABLED", "false").lower() == "true"
    if osv_enabled:
        try:
            # Query for recent CVEs (example query - adjust as needed)
            query = {
                "query": "type:ECOSYSTEM",
                "page_size": 100
            }
            osv_vulns = fetch_osv(query)
            
            for vuln in osv_vulns:
                normalized = normalize_osv(vuln)
                if normalized["id"].startswith("CVE-"):
                    chunks = ingest_normalized(normalized, "osv")
                    results["osv"]["count"] += 1
                    results["osv"]["chunks"] += chunks
            
            _stats["osv"]["total_chunks"] = results["osv"]["chunks"]
            _stats["osv"]["last_refresh_at"] = datetime.utcnow().isoformat()
        except Exception as e:
            print(f"Error refreshing OSV: {e}")
    
    return results

