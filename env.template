PUBLIC_WEB_ORIGIN=http://localhost:3000
NEXT_PUBLIC_API_URL=http://localhost:7070
JAWSDB_URL=mysql://kt1mt8pirpoxzkfl:vykj724nlpi3y3qb@r4919aobtbi97j46.cbetxkdyhwsb.us-east-1.rds.amazonaws.com:3306/pa8ah0pwtssyutkg
API_SIGNING_SECRET=change_me_signing
RAG_SERVICE_KEY=change_me_rag
NV_SERVICE_KEY=change_me_nv
V_SERVICE_KEY=change_me_v
JWT_KEY=dev_jwt
OLLAMA_URL=http://host.docker.internal:11434
# Use quantized models for faster inference (Q4_0 = 4-bit quantization, faster than full precision)
GEN_MODEL=llama3.2:3b  # Already small, but consider llama3.2:1b for even faster responses
GEN_MODEL_LARGE=llama3.1:8b  # Consider llama3.1:8b-q4_0 for faster large model
EMBED_MODEL=nomic-embed-text  # Embedding model is already optimized
PINECONE_API_KEY=pcsk_4to45p_4d6m1ZF6HP8sskDNsrjqSmx2ScQRJH27Goaj5coaoT9DpH8me2WFzmHSytQkGzt
PINECONE_ENVIRONMENT=us-east1-gcp
PINECONE_INDEX=cve-index

JAWSDB_NV_URL=mysql://gh1blsnircwjlq9y:xleptro1zrsn4bw1@kil9uzd3tgem3naa.cbetxkdyhwsb.us-east-1.rds.amazonaws.com:3306/ab9yovws0lt9jejt

JAWSDB_V_URL=mysql://iasgy84gg7w7g2ad:duolxpyuoj63n418@j1r4n2ztuwm0bhh5.cbetxkdyhwsb.us-east-1.rds.amazonaws.com:3306/deq6zk1b37ghnan7


ADMIN_API_KEYS=demo-admin-key-123
